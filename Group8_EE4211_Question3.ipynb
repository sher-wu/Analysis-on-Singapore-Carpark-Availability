{"cells":[{"cell_type":"markdown","metadata":{"id":"5CdR-mbupA6I"},"source":["# **EE4211               Question 3**"]},{"cell_type":"markdown","metadata":{"id":"0Luw9wn1WPuI"},"source":["# **Question 3.1**\r\n","> #### At this point, you understand the data quite well. Carry out the analysis you proposed in your group project proposal. You should use the dataset given but you may also use additional datasets to supplement your analysis, look at unaggregated data, etc. Please be sure to justify why the analysis is useful and interesting in the context of a data science project. Note that you are not limited to the initial proposal and are free to expand on it."]},{"cell_type":"markdown","metadata":{"id":"mCRoNolnIF3D"},"source":["### **Clustering data pre-processing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wMcLYL2AQ2BI"},"outputs":[],"source":["import pandas as pd\r\n","Data = pd.read_excel('Car_Park_Slots.xlsx', sheet_name = None)\r\n","sheet_names = list(Data.keys())[1:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_0ywg8QBSQAb"},"outputs":[],"source":["import math\r\n","def get_data(sheet_name):\r\n","    data = Data[sheet_name]\r\n","    data = data[data.Type=='C'] # get the data that type == c\r\n","    data.loc[:, 'Rate'] = data['Available'] / data['Total']\r\n","    data.dropna(inplace=True)\r\n","    data.loc[data.Rate > 1, 'Rate'] = 1\r\n","    return data\r\n","\r\n","AvailableRate = []\r\n","Dict = {}\r\n","count = 0\r\n","data = get_data(sheet_names[0])\r\n","\r\n","for row in data.index:\r\n","    if math.isnan(data.loc[row]['Rate']) == False:\r\n","        Dict[data.loc[row]['Name']] = count\r\n","        count += 1\r\n","        AvailableRate.append([data.loc[row]['Rate']])\r\n","\r\n","for i in range(1, len(sheet_names)):\r\n","    data = get_data(sheet_names[i])\r\n","    for row in data.index:\r\n","        if data.loc[row]['Name'] in Dict and math.isnan(data.loc[row]['Rate']) == False:\r\n","            AvailableRate[Dict[data.loc[row]['Name']]].append(data.loc[row]['Rate'])\r\n","    for j in range(len(AvailableRate)):\r\n","        if len(AvailableRate[j]) <= i:\r\n","            AvailableRate[j].append(AvailableRate[j][-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aeVpUBEHtpmE"},"outputs":[],"source":["# Avaialbe rate contains the availabilities of each parking lot for the past 744 time nodes.\n","CarParksName = []\n","AvailableRateUpd = []\n","for name, id in Dict.items():\n","    check = False\n","    val0 = AvailableRate[id][0]\n","    for val in AvailableRate[id]:\n","        if val0 != val:\n","            check = True\n","            break\n","    if check:\n","        CarParksName.append(name)\n","        AvailableRateUpd.append(AvailableRate[id])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17493,"status":"ok","timestamp":1668048927770,"user":{"displayName":"Michelle Zhang","userId":"12813869600060747891"},"user_tz":-480},"id":"ovqY9_-NHQKE","outputId":"5c8893c8-c284-48fe-bada-c64f54ffd26f"},"outputs":[{"name":"stdout","output_type":"stream","text":["clusters : 2 silhouette_score : 0.398189151107227\n","clusters : 3 silhouette_score : 0.36156209549514334\n","clusters : 4 silhouette_score : 0.3303543648593959\n","clusters : 5 silhouette_score : 0.33384719792281514\n","clusters : 6 silhouette_score : 0.29413126288575775\n","clusters : 7 silhouette_score : 0.30218335365404053\n","clusters : 8 silhouette_score : 0.2720418518680833\n","clusters : 9 silhouette_score : 0.27626677523551546\n","clusters : 10 silhouette_score : 0.277635660159477\n"]}],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.cluster import KMeans\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","\n","x = np.array(AvailableRateUpd)\n","\n","for i in range(2, 11):\n","    k_means = KMeans(n_clusters=i, random_state=10)\n","    k_means.fit(x)\n","\n","    y_predict = k_means.predict(x)\n","    print(\"clusters : \" + str(i), end = \"\")\n","    # plt.show()\n","    # print(k_means.predict((x[:30,:])))\n","    # print(k_means.cluster_centers_)\n","    # print(k_means.inertia_)\n","    print(\" silhouette_score : \" + str(metrics.silhouette_score(x,y_predict)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uvzf-9OadsyD"},"outputs":[],"source":["from numpy import savetxt\r\n","k_means = KMeans(n_clusters=2, random_state=10)\r\n","k_means.fit(x)\r\n","y_predict = k_means.predict(x)\r\n","\r\n","model_i = pd.DataFrame(y_predict, columns = ['model'])\r\n","\r\n","carpark_ = []\r\n","for i in CarParksName:\r\n","    carpark_.append(i)\r\n","carpark_ = pd.DataFrame(carpark_, columns = ['Name'])\r\n","\r\n","print(model_i)\r\n","print(carpark_)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xcwUwV1-zelm"},"outputs":[],"source":["import csv\n","\n","with open('NameandClass.csv', 'w', encoding='utf-8') as file_obj:\n","    writer = csv.writer(file_obj)\n","    writer.writerow(['Name', 'Class'])\n","    for i in range(len(y_predict)):\n","        writer.writerow([CarParksName[i], y_predict[i]])\n","\n","center = k_means.cluster_centers_\n","with open('ClusterCenter.csv', 'w', encoding='utf-8') as file_obj:\n","    writer = csv.writer(file_obj)\n","    writer.writerow(['Class 0', 'Class 1'])\n","    for i in range(len(center[0])):\n","        writer.writerow([center[0][i], center[1][i]])"]},{"cell_type":"markdown","metadata":{"id":"xl2vwp9ko7cg"},"source":["#### Predicting the available parking spaces around the destination at a given moment is extremely useful in our daily life. When going to an unfamiliar place, you are highly unconfident with successful parking since you need to know how many parking lots are left around the destination. Thus, accurate prediction results will save commuting time and make your day. \r\n","\r\n","#### As our project proposal suggested, we would like to predict the future empty rate for EVERY carpark. Since modelling one regressor for every carpark is over-expensive, we first clustered the data set (using October 2021 dataset) into clusters by using the K-means clustering algorithm. K-means clustering is an easy but efficient unsupervised clustering algorithm that can properly group samples together. In the clustering process, every carpark has the following features: 1. its name; 2. its empty rate over the past 744 samples. Those two features are sufficient for our requirements since we are only focusing on the open rate for each carpark and trying to group them by their behaviour on the empty rate. By looking at the silhouette scores, we can tell how effective the clustering is. The silhouette score is a coefficient that indicates how cohesive the sample is in a cluster. When silhouette scores approach 1, the samples are clustered reasonably. When silhouette scores approach -1, the samples are clustered unreasonably. By running a series of test on the number of clusters from 2 to 10, we concluded that the silhouette scores is the highest; thus, the samples are best clustered when the number of clusters is 2.\r\n","\r\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2039,"status":"ok","timestamp":1667968864180,"user":{"displayName":"jingkei hau","userId":"05628426788392008601"},"user_tz":-480},"id":"VAKSRqjDu3BA","outputId":"b0b47017-a768-45e8-8d17-0524885766dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["clusters : 10[1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1]\n","[[0.54766771 0.54216758 0.53976819 ... 0.57436899 0.56519102 0.55341931]\n"," [0.24084325 0.2391177  0.23718832 ... 0.26004434 0.26273662 0.25418812]]\n","36156.703667259324\n"," silhouette_score : 0.398189151107227\n"]}],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.cluster import KMeans\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","\n","x = np.array(AvailableRateUpd)\n","\n","k_means = KMeans(n_clusters=2, random_state=10)\n","k_means.fit(x)\n","\n","y_predict = k_means.predict(x)\n","print(\"clusters : \" + str(i), end = \"\")\n","plt.show()\n","print(k_means.predict((x[:30,:])))\n","print(k_means.cluster_centers_)\n","print(k_means.inertia_)\n","print(\" silhouette_score : \" + str(metrics.silhouette_score(x,y_predict)))\n"]},{"cell_type":"markdown","metadata":{"id":"RdkA7I7CpK6l"},"source":["#### To make real-time carpark calculation and navigation possible, we introduced carparks' [geographic location](https://data.gov.sg/dataset/hdb-carpark-information) by combining carparks' geolocation and car parks name into our system. The destination navigation feature is possible with the help of [Onemap](https://www.onemap.gov.sg/docs/) (developed by the Singapore Land Authority) application programming interface.\r\n","\r\n","#### To project cluster results to the map of Singapore, We use red and blue dots to visualize the two clusters of parking lots in terms of geographic coordinates. The graph shows that the two kinds of parking lots are interleaved together, which indicates that the clustering result is not related to geographical coordinates but the variation pattern of the empty rate. The results also show that drivers tend to choose the desired carpark randomly.\r\n","\r\n","![picture](./images/Carpark_map.png)"]},{"cell_type":"markdown","metadata":{"id":"8uvJwbvwpN2c"},"source":["# **Question 3.2**\r\n","> #### Based on the insights derived from the analysis, suggest a practical action that can be taken (i.e., an action that can be taken to benefit society. Do not suggest actions such as hyperparameter tuning here)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q8YnEq2Ypims"},"outputs":[],"source":["from urllib.request import Request, urlopen\n","import json\n","import urllib\n","import math\n","from queue import PriorityQueue"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Z4e-_Gcpn4F"},"outputs":[],"source":["def extract(offset=0):\r\n","    url = 'https://data.gov.sg/api/action/datastore_search?offset=%d&resource_id=139a3035-e624-4f56-b63f-89ae28d4ae4c' % (offset)\r\n","    headers = {'User-Agent': 'Mozilla/5.0'}\r\n","    req = urllib.request.Request(url,headers=headers)\r\n","    response = urllib.request.urlopen(req)\r\n","    hjson = json.loads(response.read())\r\n","\r\n","    return hjson"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p0pEwXaQpphH"},"outputs":[],"source":["def getDistance(x,y,record):\r\n","    x1 = float(record['x_coord'])\r\n","    y1 = float(record['y_coord'])\r\n","\r\n","    return math.sqrt((x-x1)**2+(y-y1)**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjK1EaKwpsXh"},"outputs":[],"source":["# Retreive the nearest k carparks by entering the lat and long and lat coordination.\r\n","# return: list that contains the nearest k carparks info\r\n","# x: long coordinate\r\n","# y: lat  coordinate\r\n","# k: Number of carparks\r\n","\r\n","def getNearestK(x, y, k):\r\n","    offset = 0\r\n","    pq = PriorityQueue()\r\n","    while True:\r\n","        hjson = extract(offset)\r\n","        if len(hjson['result']['records']) == 0:\r\n","            break \r\n","        for record in hjson['result']['records']:\r\n","            dist = -getDistance(x, y, record)\r\n","            if pq.qsize() == k:\r\n","                top, topRecord = pq.get()\r\n","                if(top>dist):\r\n","                    pq.put((top,topRecord))\r\n","                else:\r\n","                    pq.put((dist,record))\r\n","            else:\r\n","                pq.put((dist,record))\r\n","        offset += 100\r\n","\r\n","    ans = []\r\n","    while (not pq.empty()):\r\n","        top = pq.get()\r\n","        ans.append((-top[0],top[1]))\r\n","    return ans"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = getNearestK(0, 0, 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k_nwJBJTrnxN"},"outputs":[],"source":["# Get the nearest K carparks' information.\r\n","# return:           dataframe that contains the nearest k carparks address, carpark name, address, and cluster tag\r\n","# nearest_carparks: return values from getNearestK function;\r\n","# k:                Number of carparks\r\n","\r\n","def getNearestK_info(nearest_carparks, k):\r\n","\r\n","  nearest_carparks_info = pd.DataFrame(columns=['car_park_no','address','cluster_tag'])\r\n","  cluster_tag = pd.read_csv(\"NameandClass.csv\")\r\n","\r\n","  for i in range(k):\r\n","    car_park_no = nearest_carparks[i][1]['car_park_no']\r\n","    carpark_ctag = cluster_tag[cluster_tag['Name']==car_park_no]['Class'].tolist()\r\n","    if len(carpark_ctag) == 0:#Drop the carpark if no empty rate applicatble\r\n","      continue\r\n","    carpark_info = pd.DataFrame([[car_park_no,nearest_carparks[i][1]['address'],carpark_ctag[0]]], columns=['car_park_no','address','cluster_tag'])\r\n","    \r\n","    nearest_carparks_info = nearest_carparks_info.append(carpark_info,ignore_index=True)\r\n","\r\n","  return nearest_carparks_info"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1668058910588,"user":{"displayName":"Michelle Zhang","userId":"12813869600060747891"},"user_tz":-480},"id":"xYG__yUbDBDx","outputId":"c086a48c-4c1b-4d15-aec8-47852ca70334"},"outputs":[{"name":"stdout","output_type":"stream","text":["  car_park_no                             address cluster_tag\n","0        J62M       BLK 901 JURONG WEST STREET 91           0\n","1        JM24       BLK 655 JURONG WEST STREET 61           0\n","2         C38  BLK 715-717 CLEMENTI WEST STREET 2           1\n","3        JM28           BLK 990 JURONG WEST ST 93           0\n"]}],"source":["nearestK_carparks_info = getNearestK_info(x, 5)\r\n","print(nearestK_carparks_info)"]},{"cell_type":"markdown","metadata":{"id":"Spb90T8Lt3DC"},"source":["### **Regressors Training**"]},{"cell_type":"markdown","metadata":{"id":"GPn83zZcpf5L"},"source":["#### To train the regreesors that can predict carpark's empty rate in futre, we used the history data from 2021 oct as our train and test dataset.\r\n","\r\n","#### After the K-means clustering, every carpark has a unique tag to determine which group it belongs to and which regressor it should use to predict future empty rates. We trained two decision tree regression models and two support vector regressor models to predict carparks' empty rate. **The features we used in regressors are 1. Departure date; 2. Expected arrival time; 3. Workday/Weekend or Holiday. The label is the average empty rate of the selected cluster at the given time.** According to our test results, those two models accurately predict carparks' emtpy rate. The R^2 scores are 0.964 and 0.967 on our test data. With this application, drivers can avoid driving from one carpark to another to find an available parking space after arriving at the place. This application will ease drivers' pain of searching for parking lots and improve road utilization.\r\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G06d9tXxRxoT"},"outputs":[],"source":["import pandas as pd\n","import sklearn\n","import numpy as np\n","from sklearn.tree import DecisionTreeRegressor\n","import matplotlib.pyplot as plt\n","from sklearn.svm import SVR\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import GridSearchCV\n","%matplotlib inline "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t09YS_jkR6Rz"},"outputs":[],"source":["# Get training and testing data ready\r\n","import datetime\r\n","\r\n","aggregated = [[] for i in range(744)]\r\n","year = 2021\r\n","month = 10\r\n","for day in range(1, 32):\r\n","    for hour in range(24):\r\n","        aggregated[(day-1)*24+hour].append(day - 92)\r\n","        aggregated[(day-1)*24+hour].append(hour)\r\n","        if datetime.date(year, month, day).weekday() >= 5:\r\n","            aggregated[(day-1)*24+hour].append(1)\r\n","        else:\r\n","            aggregated[(day-1)*24+hour].append(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Oph_BtXS-lY"},"outputs":[],"source":["# Train test data split; 70% training data; 30% testing data\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","dataset = pd.DataFrame(aggregated)\r\n","dataset_cluster0 = pd.concat([dataset,pd.read_csv('ClusterCenter.csv')['Class 0']],axis = 1)\r\n","dataset_cluster1 = pd.concat([dataset,pd.read_csv('ClusterCenter.csv')['Class 1']],axis = 1)\r\n","\r\n","\r\n","x_train_0, x_test_0, y_train_0, y_test_0 = train_test_split(dataset_cluster0.loc[:,:2], dataset_cluster0['Class 0'], test_size=0.3)\r\n","x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(dataset_cluster1.loc[:,:2], dataset_cluster1['Class 1'], test_size=0.3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1668065437996,"user":{"displayName":"Michelle Zhang","userId":"12813869600060747891"},"user_tz":-480},"id":"MIOXrFQmsb2_","outputId":"2a06fe4b-a1d9-484f-9e22-a0e4c16e47a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.963956591964612\n","0.966709076098193\n"]}],"source":["# DTR for 2 models\r\n","model = [DecisionTreeRegressor(), DecisionTreeRegressor()]\r\n","model[0].fit(x_train_0, y_train_0)\r\n","model[1].fit(x_train_1, y_train_1)\r\n","\r\n","print(model[0].score(x_test_0, y_test_0))\r\n","print(model[1].score(x_test_1, y_test_1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1668065792302,"user":{"displayName":"Michelle Zhang","userId":"12813869600060747891"},"user_tz":-480},"id":"xPe_HahIsgw-","outputId":"c7b1f5c6-eeba-4e5c-cf7e-52a5717b69bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["-0.03845521242917194\n","0.03464442403106449\n"]}],"source":["# SVR for 2 models\r\n","from sklearn.preprocessing import RobustScaler\r\n","\r\n","rbX = RobustScaler()\r\n","\r\n","x_train_scaler_0 = rbX.fit_transform(x_train_0)\r\n","x_test_scaler_0 = rbX.transform(x_test_0)\r\n","\r\n","x_train_scaler_1 = rbX.fit_transform(x_train_1)\r\n","x_test_scaler_1 = rbX.transform(x_test_1)\r\n","\r\n","model_SVR = [SVR(kernel = 'rbf'), SVR(kernel = 'rbf')]\r\n","model_SVR[0].fit(x_train_scaler_0, y_train_0)\r\n","model_SVR[1].fit(x_train_scaler_1, y_train_1)\r\n","\r\n","print(model_SVR[0].score(x_test_scaler_0, y_test_0))\r\n","print(model_SVR[1].score(x_test_scaler_1, y_test_1))"]},{"cell_type":"markdown","metadata":{"id":"-f-ueR_JeYaI"},"source":["#### **According to the R^2 results, DTR has a much better performance than SVR, thus we will focusing on DTR to do the parameter tuning**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1415,"status":"ok","timestamp":1668066345313,"user":{"displayName":"Michelle Zhang","userId":"12813869600060747891"},"user_tz":-480},"id":"JkljUm_OskQu","outputId":"5d3e4626-a0c0-4523-f492-42bf4d5cab5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["When max_Depth =  15:\n","DTR for cluster 0 has the best performance 0.9639712652333822\n","When max_Depth =  20:\n","DTR for cluster 1 has the best performance 0.9668871464930775\n"]}],"source":["# Hyper parameter tuning\r\n","dtr_performance0 = []\r\n","dtr_performance1 = []\r\n","range_max_depth = np.arange(3,30, 1)\r\n","\r\n","\r\n","for i in range(3,30,1):\r\n","  model = [DecisionTreeRegressor(max_depth = i), DecisionTreeRegressor(max_depth = i)]\r\n","  model[0].fit(x_train_0, y_train_0)\r\n","  model[1].fit(x_train_1, y_train_1)\r\n","\r\n","  dtr_performance0.append(model[0].score(x_test_0, y_test_0))\r\n","  dtr_performance1.append(model[1].score(x_test_1, y_test_1))\r\n","\r\n","dtr_performance0 = np.array(dtr_performance0)\r\n","dtr_performance1 = np.array(dtr_performance1)\r\n","print(\"When max_Depth =  {}:\".format(range_max_depth[dtr_performance0.argmax()]))\r\n","print(\"DTR for cluster 0 has the best performance {}\".format(dtr_performance0[dtr_performance0.argmax()]))\r\n","print(\"When max_Depth =  {}:\".format(range_max_depth[dtr_performance1.argmax()]))\r\n","print(\"DTR for cluster 1 has the best performance {}\".format(dtr_performance1[dtr_performance1.argmax()]))"]},{"cell_type":"markdown","metadata":{"id":"1HjC3gDhgK9N"},"source":["#### Our testing revealed that the models perform at their peak when \"max depth\" is 15 and 20, respectively. Because the tree will automatically grow until all of its leaves are pure or contain fewer samples than min samples split. However, because the leaf nodes are too pure, the model overfits and loses its capacity to generalize to unseen data. To avoid the model from overfitting, we change the max depth in this regard."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1668066693694,"user":{"displayName":"Michelle Zhang","userId":"12813869600060747891"},"user_tz":-480},"id":"007AEu4dhTEr","outputId":"269803bc-e0a2-40fb-94b0-09efffd87e26"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9639731120236347\n","0.9666633418953358\n"]}],"source":["model = [DecisionTreeRegressor(max_depth = 15), DecisionTreeRegressor(max_depth = 20)]\n","model[0].fit(x_train_0, y_train_0)\n","model[1].fit(x_train_1, y_train_1)\n","\n","print(model[0].score(x_test_0, y_test_0))\n","print(model[1].score(x_test_1, y_test_1))"]},{"cell_type":"markdown","metadata":{"id":"f7aZe3P2aq2A"},"source":["  <br/>\n","    <br/>\n","      <br/>\n","        <br/>\n","          <br/>\n","            <br/>\n","    <br/>\n","      <br/>\n","        <br/>\n","          <br/>\n","              <br/>\n","          <br/>"]},{"cell_type":"markdown","metadata":{"id":"vcDK0FFQhuyS"},"source":["### **Demo**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XvH1Bgbui3ph"},"outputs":[],"source":["# Demonstrate how to run neaest K first and regressor to get final output empty rate\r\n","x=getNearestK(100,95,10) #find the nearest 10 carpark at lag = 100; lag = 95\r\n","nearestK_carparks_info = getNearestK_info(x,5) #get the cluster tags and address information in plain english"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1668067651016,"user":{"displayName":"Michelle Zhang","userId":"12813869600060747891"},"user_tz":-480},"id":"9Ei8xZhAswTm","outputId":"486a058a-db94-4ac7-f81d-929b62d7121f"},"outputs":[{"name":"stdout","output_type":"stream","text":["  car_park_no                                     address cluster_tag  \\\n","0        TJ27                    BLK 151/154 YUNG HO ROAD           1   \n","1         J62           BLK 902/908 JURONG WEST STREET 91           1   \n","2        JM20               BLK 657 JURONG WEST STREET 65           0   \n","3         C37  BLK 720-727,730-731 CLEMENTI WEST STREET 2           1   \n","4        J62M               BLK 901 JURONG WEST STREET 91           0   \n","\n","   empty rate  \n","0    0.276897  \n","1    0.276897  \n","2    0.572074  \n","3    0.276897  \n","4    0.572074  \n"]}],"source":["# Date from 2022.01.01, Hour, Weekday or not weekday\n","queryDate = [[315, 11, 1]]  # Use this time to as the arrive time\n","empty_rates = []\n","for i in range(nearestK_carparks_info.shape[0]):\n","  tag = nearestK_carparks_info.iloc[i]['cluster_tag']\n","  empty_rates.append(model[tag].predict(queryDate)[0]) # Select model according to the cluster tag of each carpark and predict\n","\n","empty_rates = pd.DataFrame(empty_rates,columns =['empty rate'])\n","nearestK_carparks_info = pd.concat([nearestK_carparks_info,empty_rates],axis =1)\n","print(nearestK_carparks_info)"]},{"cell_type":"markdown","metadata":{"id":"832RGpIJjxlU"},"source":["### **User interface mockup**\r\n","\r\n","A mockup user interface of the product shown below. We showed how to use the product and the process in the form of pictures and text.\r\n","\r\n","> 1. Open the Application, the location function will locate user's current location;<br/>\r\n","2. Key in the destination;<br/>\r\n","3. Key in the time of departure and the traveling method;<br/>\r\n","4. Display the number of available parking spaces in the parking lot that around the destination address.\r\n","\r\n","![picture](./images/merged.png)"]},{"cell_type":"markdown","metadata":{"id":"XZEbwABsaA2O"},"source":["# **Appendix**"]},{"cell_type":"markdown","metadata":{"id":"ZDh4i8izaSUv"},"source":["## Code for generating the scatter on SINGAPORE map"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2P9lXNihaAU2"},"outputs":[],"source":["import csv\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8frtkMFQaH-G"},"outputs":[],"source":["f1 = pd.read_csv('hdb-carpark-information.csv')\n","f2 = pd.read_csv('NameandClass.csv')\n","\n","f1 = f1.rename(columns={'car_park_no':'Name','x_coord':'x','y_coord':'y'})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGvus12FaLxR"},"outputs":[],"source":["df = pd.merge(f1,f2)\n","df1 = df.loc[df.Class==1]\n","df0 = df.loc[df.Class==0]\n","\n","px1 = df1['x'].tolist()\n","py1 = df1['y'].tolist()\n","px0 = df0['x'].tolist()\n","py0 = df0['y'].tolist()\n","\n","from PIL import Image\n","fig = plt.figure(figsize=(12,6))\n","# plt.imshow(image)\n","plt.scatter(px1,py1,c='r',s=10)\n","plt.scatter(px0,py0,c='b',s=10)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.7.4 64-bit","name":"python374jvsc74a57bd0d94ea807e9dd88dec85d6135010093db08445b4f78f2386ac1d177de969ce657"},"language_info":{"name":"python","version":""},"metadata":{"interpreter":{"hash":"d94ea807e9dd88dec85d6135010093db08445b4f78f2386ac1d177de969ce657"}}},"nbformat":4,"nbformat_minor":0}